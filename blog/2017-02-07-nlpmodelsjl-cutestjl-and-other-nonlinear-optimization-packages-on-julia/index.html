<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>NLPModels.jl, CUTEst.jl and other Nonlinear Optimization Packages on Julia | Abel Soares Siqueira</title><meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content="A couple of weeks ago me and Professor Dominique Orban have finally made a release of CUTEst.jl, a wrapper for the CUTEst repository of problems for nonlinear optimization (which I&rsquo;ve mentioned before). Along with this release, we&rsquo;ve done a release of NLPModels.jl, the underlying package. I think it&rsquo;s time I explain a little about these packages, others, and how to use them together. If you want to see the output of the commands, you can open this ASCIInema side by side."><meta name=generator content="Hugo 0.109.0"><meta name=robots content="noindex, nofollow"><link rel=stylesheet href=/ananke/css/main.min.css><link rel="shortcut icon" href=/images/icon.png type=image/x-icon><meta property="og:title" content="NLPModels.jl, CUTEst.jl and other Nonlinear Optimization Packages on Julia"><meta property="og:description" content="A couple of weeks ago me and Professor Dominique Orban have finally made a release of CUTEst.jl, a wrapper for the CUTEst repository of problems for nonlinear optimization (which I&rsquo;ve mentioned before). Along with this release, we&rsquo;ve done a release of NLPModels.jl, the underlying package. I think it&rsquo;s time I explain a little about these packages, others, and how to use them together. If you want to see the output of the commands, you can open this ASCIInema side by side."><meta property="og:type" content="article"><meta property="og:url" content="https://abelsiqueira.com/blog/2017-02-07-nlpmodelsjl-cutestjl-and-other-nonlinear-optimization-packages-on-julia/"><meta property="article:section" content="blog"><meta property="article:published_time" content="2017-02-07T00:00:00+00:00"><meta property="article:modified_time" content="2017-02-07T00:00:00+00:00"><meta property="og:site_name" content="Abel Soares Siqueira"><meta itemprop=name content="NLPModels.jl, CUTEst.jl and other Nonlinear Optimization Packages on Julia"><meta itemprop=description content="A couple of weeks ago me and Professor Dominique Orban have finally made a release of CUTEst.jl, a wrapper for the CUTEst repository of problems for nonlinear optimization (which I&rsquo;ve mentioned before). Along with this release, we&rsquo;ve done a release of NLPModels.jl, the underlying package. I think it&rsquo;s time I explain a little about these packages, others, and how to use them together. If you want to see the output of the commands, you can open this ASCIInema side by side."><meta itemprop=datePublished content="2017-02-07T00:00:00+00:00"><meta itemprop=dateModified content="2017-02-07T00:00:00+00:00"><meta itemprop=wordCount content="1883"><meta itemprop=keywords content="julia,optimization,nlpmodels,cutest,work,juliasmoothoptimizers,tutorial,"><meta name=twitter:card content="summary"><meta name=twitter:title content="NLPModels.jl, CUTEst.jl and other Nonlinear Optimization Packages on Julia"><meta name=twitter:description content="A couple of weeks ago me and Professor Dominique Orban have finally made a release of CUTEst.jl, a wrapper for the CUTEst repository of problems for nonlinear optimization (which I&rsquo;ve mentioned before). Along with this release, we&rsquo;ve done a release of NLPModels.jl, the underlying package. I think it&rsquo;s time I explain a little about these packages, others, and how to use them together. If you want to see the output of the commands, you can open this ASCIInema side by side."><script type=text/javascript src=https://cdn.jsdelivr.net/gh/pcooksey/bibtex-js@1.0.0/src/bibtex_js.min.js></script></head><body class="ma0 avenir bg-near-white"><header><div class=bg-dark-blue><nav class="pv3 ph3 ph4-ns" role=navigation><div class="flex-l justify-between items-center center"><a href=/ class="f3 fw2 hover-white no-underline white-90 dib"><img src=/images/logo.png class="w100 mw5-ns" alt="Abel Soares Siqueira"></a><div class="flex-l items-center"><ul class="pl0 mr3"><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/blog/ title="Blog page">Blog</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/projects/ title="Projects page">Projects</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/resume/ title="Resume page">Resume</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/youtube/ title="YouTube page">YouTube</a></li></ul><div class=ananke-socials><a href=https://twitter.com/abel_siqueira target=_blank rel=noopener class="twitter ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="Twitter link" aria-label="follow on Twitter——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167 22.283c-2.619.953-4.274 3.411-4.086 6.101l.063 1.038-1.048-.127c-3.813-.487-7.145-2.139-9.974-4.915l-1.383-1.377-.356 1.017c-.754 2.267-.272 4.661 1.299 6.271.838.89.649 1.017-.796.487-.503-.169-.943-.296-.985-.233-.146.149.356 2.076.754 2.839.545 1.06 1.655 2.097 2.871 2.712l1.027.487-1.215.021c-1.173.0-1.215.021-1.089.467.419 1.377 2.074 2.839 3.918 3.475l1.299.444-1.131.678c-1.676.976-3.646 1.526-5.616 1.568C19.775 43.256 19 43.341 19 43.405c0 .211 2.557 1.397 4.044 1.864 4.463 1.377 9.765.783 13.746-1.568 2.829-1.673 5.657-5 6.978-8.221.713-1.716 1.425-4.851 1.425-6.354.0-.975.063-1.102 1.236-2.267.692-.678 1.341-1.419 1.467-1.631.21-.403.188-.403-.88-.043-1.781.636-2.033.551-1.152-.402.649-.678 1.425-1.907 1.425-2.267.0-.063-.314.042-.671.233-.377.212-1.215.53-1.844.72l-1.131.361-1.027-.7c-.566-.381-1.361-.805-1.781-.932C39.766 21.902 38.131 21.944 37.167 22.283zM33 64C16.432 64 3 50.569 3 34S16.432 4 33 4s30 13.431 30 30S49.568 64 33 64z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span></a><a href=https://github.com/abelsiqueira target=_blank rel=noopener class="github ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="GitHub link" aria-label="follow on GitHub——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 512 512" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M256 32C132.3 32 32 134.8 32 261.7c0 101.5 64.2 187.5 153.2 217.9 11.2 2.1 15.3-5 15.3-11.1.0-5.5-.2-19.9-.3-39.1-62.3 13.9-75.5-30.8-75.5-30.8-10.2-26.5-24.9-33.6-24.9-33.6-20.3-14.3 1.5-14 1.5-14 22.5 1.6 34.3 23.7 34.3 23.7 20 35.1 52.4 25 65.2 19.1 2-14.8 7.8-25 14.2-30.7-49.7-5.8-102-25.5-102-113.5.0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8.0.0 18.8-6.2 61.6 23.5 17.9-5.1 37-7.6 56.1-7.7 19 .1 38.2 2.6 56.1 7.7 42.8-29.7 61.5-23.5 61.5-23.5 12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6.0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5.0 30.7-.3 55.5-.3 63 0 6.1 4 13.3 15.4 11C415.9 449.1 480 363.1 480 261.7 480 134.8 379.7 32 256 32z"/></svg></span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span></a><a href=https://linkedin.com/in/abel-siqueira target=_blank rel=noopener class="linkedin ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" aria-label="follow on LinkedIn——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 65 65" viewBox="0 0 65 65" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M50.837 48.137V36.425c0-6.275-3.35-9.195-7.816-9.195-3.604.0-5.219 1.983-6.119 3.374V27.71h-6.79c.09 1.917.0 20.427.0 20.427h6.79V36.729c0-.609.044-1.219.224-1.655.49-1.22 1.607-2.483 3.482-2.483 2.458.0 3.44 1.873 3.44 4.618v10.929H50.837zM22.959 24.922c2.367.0 3.842-1.57 3.842-3.531-.044-2.003-1.475-3.528-3.797-3.528s-3.841 1.524-3.841 3.528c0 1.961 1.474 3.531 3.753 3.531H22.959zM34 64C17.432 64 4 50.568 4 34 4 17.431 17.432 4 34 4s30 13.431 30 30c0 16.568-13.432 30-30 30zM26.354 48.137V27.71h-6.789v20.427h6.789z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span></a><a href=https://mathstodon.xyz/@abelsiqueira target=_blank rel="me noopener" class="mastodon ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="Mastodon link" aria-label="follow on Mastodon——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" xmlns="http://www.w3.org/2000/svg"><path d="M61.731833 16.783448C60.855064 10.336694 55.17491 5.2562169 48.441526 4.2717554 47.305526 4.1054038 43.001372 3.5 33.030833 3.5h-.07446c-9.973232.0-12.112924.6054038-13.248924.7717554C13.161526 5.2289477 7.1836569 9.7940169 5.7332999 16.317063c-.6976035 3.212462-.7720515 6.774-.6424569 10.041.1847407 4.685077.2205861 9.361923.6507292 14.027923.2973693 3.099385.8161231 6.174077 1.552377 9.201 1.3786615 5.590462 6.9594998 10.242769 12.4272688 12.140846 5.854077 1.979385 12.149615 2.307923 18.181846.949.663539-.152692 1.319846-.33 1.968693-.531769 1.464153-.460846 3.182-.976308 4.444846-1.881692.01731-.01269.03154-.02908.04154-.048.01-.01885.01562-.03977.01631-.06108v-4.521385c-308e-6-.01992-.0051-.03954-.014-.05738-.009-.01785-.02185-.03354-.03777-.04577-.01585-.01231-.03431-.02092-.05392-.02531-.01969-.0043-.04008-.0042-.05969 23e-5-3.864769.913077-7.825154 1.370769-11.798615 1.363539-6.838154.0-8.677308-3.209693-9.204-4.546-.423308-1.154846-.692154-2.359462-.799615-3.583308-.0011-.02054.0028-.04108.01115-.05992.0084-.01877.02123-.03538.03731-.04839.01615-.013.03515-.02208.05546-.02646.02031-.0045.04138-.004.06154.0012 3.800385.906846 7.696154 1.364538 11.605615 1.363538.940231.0 1.877693.0 2.818-.02454 3.931923-.109077 8.076154-.308154 11.944693-1.055385.09654-.01908.193-.03546.275769-.06 6.101923-1.159 11.908846-4.796846 12.498923-14.008846.02208-.362692.07723-3.798769.07723-4.175077.0028-1.279.416384-9.072846-.06069-13.861538zm-9.391461 22.98623H45.924141V24.225525c0-3.272462-1.378692-4.941385-4.182923-4.941385-3.082692.0-4.626769 1.974385-4.626769 5.874v8.508385H30.736757V25.15814c0-3.899615-1.546847-5.874-4.629539-5.874-2.787692.0-4.180154 1.668923-4.182923 4.941385V39.769678H15.513526V23.753755c0-3.272461.844692-5.87223 2.534-7.799384 1.742615-1.922539 4.028461-2.909693 6.865769-2.909693 3.283923.0 5.765538 1.248923 7.419923 3.744231l1.596539 2.650692 1.59923-2.650692c1.654385-2.495308 4.136-3.744231 7.414462-3.744231 2.834538.0 5.120308.987154 6.868461 2.909693 1.689385 1.925307 2.534 4.525077 2.534 7.799384z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span></a><a href=https://instagram.com/siqueiraabel target=_blank rel=noopener class="instagram ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="Instagram link" aria-label="follow on Instagram——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M42.271 26.578v-.006c.502.0 1.005.01 1.508-.002.646-.017 1.172-.57 1.172-1.217.0-.963.0-1.927.0-2.89.0-.691-.547-1.24-1.236-1.241-.961.0-1.922-.001-2.883.0-.688.001-1.236.552-1.236 1.243-.001.955-.004 1.91.003 2.865.001.143.028.291.073.426.173.508.639.82 1.209.823C41.344 26.579 41.808 26.578 42.271 26.578zM33 27.817c-3.384-.002-6.135 2.721-6.182 6.089-.049 3.46 2.72 6.201 6.04 6.272 3.454.074 6.248-2.686 6.321-6.043C39.254 30.675 36.462 27.815 33 27.817zM21.046 31.116v.082c0 4.515-.001 9.03.0 13.545.0.649.562 1.208 1.212 1.208 7.16.001 14.319.001 21.479.0.656.0 1.215-.557 1.215-1.212.001-4.509.0-9.02.0-13.528v-.094H42.04c.411 1.313.537 2.651.376 4.014s-.601 2.631-1.316 3.803-1.644 2.145-2.779 2.918c-2.944 2.006-6.821 2.182-9.946.428-1.579-.885-2.819-2.12-3.685-3.713-1.289-2.373-1.495-4.865-.739-7.451C22.983 31.116 22.021 31.116 21.046 31.116zM45.205 49.255c.159-.026.318-.049.475-.083 1.246-.265 2.264-1.304 2.508-2.557.025-.137.045-.273.067-.409V21.794c-.021-.133-.04-.268-.065-.401-.268-1.367-1.396-2.428-2.78-2.618-.058-.007-.113-.02-.17-.03H20.761c-.147.027-.296.047-.441.08-1.352.308-2.352 1.396-2.545 2.766-.008.057-.02.114-.029.171V46.24c.028.154.05.311.085.465.299 1.322 1.427 2.347 2.77 2.52.064.008.13.021.195.03H45.205zM33 64C16.432 64 3 50.569 3 34S16.432 4 33 4s30 13.431 30 30S49.568 64 33 64z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span></a><a href=https://youtube.com/@abelsiqueira target=_blank rel=noopener class="youtube ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="YouTube link" aria-label="follow on YouTube——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M42.527 41.34c-.278.0-.478.078-.6.244-.121.156-.18.424-.18.796v.896h1.543V42.38c0-.372-.062-.64-.185-.796C42.989 41.418 42.792 41.34 42.527 41.34zM36.509 41.309c.234.0.417.076.544.23.123.155.185.383.185.682v4.584c0 .286-.053.487-.153.611-.1.127-.256.189-.47.189-.148.0-.287-.033-.421-.096-.135-.062-.274-.171-.415-.313v-5.531c.119-.122.239-.213.36-.271C36.26 41.335 36.383 41.309 36.509 41.309zm5.239 3.349v1.672c0 .468.057.792.17.974.118.181.313.269.592.269.289.0.491-.076.606-.229.114-.153.175-.489.175-1.013v-.405h1.795v.456c0 .911-.217 1.596-.657 2.059-.435.459-1.089.687-1.958.687-.781.0-1.398-.242-1.847-.731-.448-.486-.676-1.157-.676-2.014v-3.986c0-.768.249-1.398.742-1.882.493-.484 1.128-.727 1.911-.727.799.0 1.413.225 1.843.674.429.448.642 1.093.642 1.935v2.264H41.748zm-3.125 3.837c-.271.336-.669.501-1.187.501-.343.0-.646-.062-.912-.192-.267-.129-.519-.327-.746-.601v.681h-1.764V36.852h1.764v3.875c.237-.27.485-.478.748-.616.267-.143.534-.212.805-.212.554.0.975.189 1.265.565.294.379.438.933.438 1.66v4.926C39.034 47.678 38.897 48.159 38.623 48.495zM30.958 48.884v-.976c-.325.361-.658.636-1.009.822-.349.191-.686.282-1.014.282-.405.0-.705-.129-.913-.396-.201-.266-.305-.658-.305-1.189v-7.422h1.744v6.809c0 .211.037.362.107.457.077.095.196.141.358.141.128.0.292-.062.488-.188.197-.125.375-.283.542-.475v-6.744H32.7v8.878H30.958zM24.916 38.6v10.284h-1.968V38.6h-2.034v-1.748h6.036V38.6H24.916zm8.078-5.622c0-.001 12.08.018 13.514 1.45 1.439 1.435 1.455 8.514 1.455 8.555.0.0-.012 7.117-1.455 8.556C45.074 52.969 32.994 53 32.994 53s-12.079-.031-13.516-1.462c-1.438-1.435-1.441-8.502-1.441-8.556.0-.041.004-7.12 1.441-8.555 1.438-1.431 13.516-1.45 13.516-1.449zm9.526-3.723h-1.966v-1.08c-.358.397-.736.703-1.13.909-.392.208-.771.312-1.14.312-.458.0-.797-.146-1.027-.437-.229-.291-.345-.727-.345-1.311v-8.172h1.962v7.497c0 .231.045.399.127.502.08.104.216.156.399.156.143.0.327-.069.548-.206.22-.137.423-.312.605-.527v-7.422h1.966V29.255zM31.847 27.588c.139.147.339.219.6.219.266.0.476-.075.634-.223.157-.152.235-.358.235-.618v-5.327c0-.214-.08-.387-.241-.519-.16-.131-.37-.196-.628-.196-.241.0-.435.065-.586.196-.148.132-.225.305-.225.519v5.327C31.636 27.233 31.708 27.439 31.847 27.588zm-1.439-7.685c.528-.449 1.241-.674 2.132-.674.812.0 1.48.237 2.001.711.517.473.777 1.083.777 1.828v5.051c0 .836-.255 1.491-.762 1.968-.513.476-1.212.714-2.106.714-.858.0-1.547-.246-2.064-.736-.513-.492-.772-1.152-.772-1.983v-5.068C29.613 20.954 29.877 20.351 30.408 19.903zM24.262 16h-2.229l2.634 8.003v5.252h2.213v-5.5L29.454 16h-2.25l-1.366 5.298h-.139L24.262 16zM33 64C16.432 64 3 50.569 3 34S16.432 4 33 4s30 13.431 30 30S49.568 64 33 64z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span></a></div></div></div></nav></div></header><main class=pb7 role=main><article class="flex-l flex-wrap justify-between mw8 center ph3"><header class="mt4 w-100"><aside class="instapaper_ignoref b helvetica tracked">BLOG</aside><div id=sharing class="mt3 ananke-socials"><a href="https://twitter.com/share?url=https://abelsiqueira.com/blog/2017-02-07-nlpmodelsjl-cutestjl-and-other-nonlinear-optimization-packages-on-julia/&text=NLPModels.jl,%20CUTEst.jl%20and%20other%20Nonlinear%20Optimization%20Packages%20on%20Julia" class="ananke-social-link twitter no-underline" aria-label="share on Twitter"><span class=icon><svg style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167 22.283c-2.619.953-4.274 3.411-4.086 6.101l.063 1.038-1.048-.127c-3.813-.487-7.145-2.139-9.974-4.915l-1.383-1.377-.356 1.017c-.754 2.267-.272 4.661 1.299 6.271.838.89.649 1.017-.796.487-.503-.169-.943-.296-.985-.233-.146.149.356 2.076.754 2.839.545 1.06 1.655 2.097 2.871 2.712l1.027.487-1.215.021c-1.173.0-1.215.021-1.089.467.419 1.377 2.074 2.839 3.918 3.475l1.299.444-1.131.678c-1.676.976-3.646 1.526-5.616 1.568C19.775 43.256 19 43.341 19 43.405c0 .211 2.557 1.397 4.044 1.864 4.463 1.377 9.765.783 13.746-1.568 2.829-1.673 5.657-5 6.978-8.221.713-1.716 1.425-4.851 1.425-6.354.0-.975.063-1.102 1.236-2.267.692-.678 1.341-1.419 1.467-1.631.21-.403.188-.403-.88-.043-1.781.636-2.033.551-1.152-.402.649-.678 1.425-1.907 1.425-2.267.0-.063-.314.042-.671.233-.377.212-1.215.53-1.844.72l-1.131.361-1.027-.7c-.566-.381-1.361-.805-1.781-.932C39.766 21.902 38.131 21.944 37.167 22.283zM33 64C16.432 64 3 50.569 3 34S16.432 4 33 4s30 13.431 30 30S49.568 64 33 64z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span></a><a href="https://www.linkedin.com/shareArticle?mini=true&url=https://abelsiqueira.com/blog/2017-02-07-nlpmodelsjl-cutestjl-and-other-nonlinear-optimization-packages-on-julia/&title=NLPModels.jl,%20CUTEst.jl%20and%20other%20Nonlinear%20Optimization%20Packages%20on%20Julia" class="ananke-social-link linkedin no-underline" aria-label="share on LinkedIn"><span class=icon><svg style="enable-background:new 0 0 65 65" viewBox="0 0 65 65" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M50.837 48.137V36.425c0-6.275-3.35-9.195-7.816-9.195-3.604.0-5.219 1.983-6.119 3.374V27.71h-6.79c.09 1.917.0 20.427.0 20.427h6.79V36.729c0-.609.044-1.219.224-1.655.49-1.22 1.607-2.483 3.482-2.483 2.458.0 3.44 1.873 3.44 4.618v10.929H50.837zM22.959 24.922c2.367.0 3.842-1.57 3.842-3.531-.044-2.003-1.475-3.528-3.797-3.528s-3.841 1.524-3.841 3.528c0 1.961 1.474 3.531 3.753 3.531H22.959zM34 64C17.432 64 4 50.568 4 34 4 17.431 17.432 4 34 4s30 13.431 30 30c0 16.568-13.432 30-30 30zM26.354 48.137V27.71h-6.789v20.427h6.789z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span></a></div><h1 class="f1 athelas mt3 mb1">NLPModels.jl, CUTEst.jl and other Nonlinear Optimization Packages on Julia</h1><p class=tracked>By <strong>Abel Soares Siqueira</strong></p><time class="f6 mv4 dib tracked" datetime=2017-02-07T00:00:00Z>February 7, 2017</time></header><div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><p>A couple of weeks ago me and Professor <a href=https://dpo.github.io>Dominique Orban</a> have finally made a release of
CUTEst.jl, a wrapper for the CUTEst repository of problems for nonlinear
optimization (which I&rsquo;ve mentioned before).
Along with this release, we&rsquo;ve done a release of NLPModels.jl, the underlying
package. I think it&rsquo;s time I explain a little about these packages, others,
and how to use them together.
If you want to see the output of the commands, you can open
<a href=https://asciinema.org/a/102371>this ASCIInema</a>
side by side.</p><p><em>Obs.: Tutorial using Julia 0.5.0</em></p><p><em>Edit: Second part is
<a href=https://abelsiqueira.github.io%7B%7Blocal_prefix%7D%7Dnlpmodelsjl-and-cutestjl-constrained-optimization/>here</a>.</em></p><p><strong>JuliaSmoothOptimizers</strong>
<a href=https://juliasmoothoptimizers.github.io><img src=https://juliasmoothoptimizers.github.io/assets/logo.png alt="JuliaSmoothOptimizers logo">{: .img-view }</a></p><p>Most packages mentioned here will be a part of the JuliaSmoothOptimizers (JSO)
organization. There are more packages in the organization that I won&rsquo;t mention here, but you should check it out.</p><p><strong>NLPModels.jl</strong></p><p>NLPModels is a package for creating Nonlinear Optimization Models. It is
focused on the needs of the solver writer, such as the ability to write one
solver that works on many models.
The package defines a few models, and there are others on the horizon.
The ones already done are:</p><ul><li><strong>ADNLPModel</strong>: A model with automatic differentiation;</li><li><strong>MathProgNLPModel</strong>: A model for <a href=https://github.com/JuliaOpt/MathProgBase.jl>MathProgBase</a>/<a href=http://github.com/JuliaOpt/JuMP.jl>JuMP</a> conversion, whose utility will be shown below (obs: MPB and JuMP are packages from the JuliaOpt organization);</li><li><strong>SimpleNLPModel</strong>: A model in which nothing is automatic, i.e., all functions have to be provided by the user.</li><li><strong>SlackModel</strong>: A model that changes all inequalities to equalities adding extra variables;</li><li><strong>LBFGSModel</strong> and <strong>LSR1Model</strong>: Models that create quasi-Newton models from another model.</li></ul><p>The first two models are designed to be easy to use; the third is useful for
efficient model creation in specific cases; the last ones are utility models.</p><p>Let&rsquo;s begin by installing NLPModels.jl, and a couple of optional requirements.</p><pre tabindex=0><code>Pkg.add(&#34;NLPModels.jl&#34;)
Pkg.add(&#34;JuMP.jl&#34;) # Installs ForwardDiff also.
</code></pre><p>This should install version 0.1.0. After that, just do</p><pre tabindex=0><code>using NLPModels
</code></pre><p>Now, let&rsquo;s create a simple function: Rosenbrock&rsquo;s.</p><pre tabindex=0><code>f(x) = (x[1] - 1)^2 + 100*(x[2] - x[1]^2)^2
</code></pre><p>The Rosenbrock problem traditionally starts from $(-1.2,1.0)$.</p><pre tabindex=0><code>x0 = [-1.2; 1.0]
</code></pre><p>Now, we are ready to create the problem.</p><pre tabindex=0><code>adnlp = ADNLPModel(f, x0)
</code></pre><p>Now, we can access the function and derivatives using the <a href=https://juliasmoothoptimizers.github.io/NLPModels.jl/stable/api.html>NLPModels API</a></p><pre tabindex=0><code>obj(adnlp, adnlp.meta.x0)
grad(adnlp, adnlp.meta.x0)
hess(adnlp, adnlp.meta.x0)
objgrad(adnlp, adnlp.meta.x0)
hprod(adnlp, adnlp.meta.x0, ones(2))
H = hess_op(adnlp, adnlp.meta.x0)
H * ones(2)
</code></pre><p>At this point, we can&rsquo;t differentiate many things from simply using
<code>ForwardDiff</code> interface directly, but two things stand out: <code>objgrad</code> returns
both functions at once, and <code>hess_op</code> returns a
<a href=https://github.com/JuliaSmoothOptimizers/LinearOperators.jl>LinearOperator</a>,
another structure created in JuliaSmoothOptimizers.
This one defines a linear operator, extending Julia matrices in the sense that if</p><pre tabindex=0><code>using LinearOperators
n = 100
A = rand(n, n)
B = rand(n, n)
opA = LinearOperator(A)
opB = LinearOperator(B)
v = rand(n)
</code></pre><p>then <code>(A * B) * v</code> computes the matrix product, whereas <code>(opA * opB) * v</code> won&rsquo;t.
Furthermore, the linear operator can be created from the functions
<code>v->Mp(v)</code> and <code>v->Mtp(v)</code>, defining the product of the linear operator times a vector and its transpose times a vector.</p><pre tabindex=0><code>T = LinearOperator(2, 2, # sizes
                   false, false,
                   v-&gt;[-v[2]; v[1]], v-&gt;[v[2]; -v[1]])
v = rand(2)
T * v
T&#39; * v
</code></pre><p><em>Obs: In the <code>ADNLPModel</code> case, <code>hess_op</code> returns a linear operator that is actually
computing the matrix, but this is a issue to be tackled on the future (PRs
welcome). But we&rsquo;ll be back with uses for <code>hess_op</code> soon.</em></p><p>The next model is the <code>MathProgNLPModel</code>. This model&rsquo;s main use is the <code>JuMP</code>
modelling language. This is very useful for more elaborate writing, specially
with constraints. It does create a little more overhead though, so keep that
in mind.</p><pre tabindex=0><code>using JuMP
jmp = Model()
@variable(jmp, x[i=1:2], start=(x0[i])) # x0 from before
@NLobjective(jmp, Min, (x[1] - 1)^2 + 100*(x[2] - x[1]^2)^2)
mpbnlp = MathProgNLPModel(jmp)
</code></pre><p>Try the commands again.</p><pre tabindex=0><code>obj(mpbnlp, mpbnlp.meta.x0)
grad(mpbnlp, mpbnlp.meta.x0)
hess(mpbnlp, mpbnlp.meta.x0)
objgrad(mpbnlp, mpbnlp.meta.x0)
hprod(mpbnlp, mpbnlp.meta.x0, ones(2))
H = hess_op(mpbnlp, mpbnlp.meta.x0)
H * ones(2)
</code></pre><p>It should be pretty much the same, though there is a little difference in <code>hess</code>.
JuMP creates the sparse Hessian, which is better, from a computational point of
view.</p><p>Notice how the commands are the same. I&rsquo;ve actually copy-pasted the commands
from above.
This allows the write of a solver in just a couple of commands.
For instance, a simple <strong>Newton method</strong>.</p><pre tabindex=0><code>function newton(nlp :: AbstractNLPModel)
  x = nlp.meta.x0
  fx = obj(nlp, x)
  gx = grad(nlp, x)
  ngx = norm(gx)
  while ngx &gt; 1e-6
    Hx = hess(nlp, x)
    d = -gx
    try
      G = chol(Hermitian(Hx, :L)) # Make Cholesky work on lower-only matrix.
      d = -G\(G&#39;\gx)
    catch e
      if !isa(e, Base.LinAlg.PosDefException); rethrow(e); end
    end
    t = 1.0
    xt = x + t * d
    ft = obj(nlp, xt)
    while ft &gt; fx + 0.5 * t * dot(gx, d)
      t *= 0.5
      xt = x + t * d
      ft = obj(nlp, xt)
    end
    x = xt
    fx = ft
    gx = grad(nlp, x)
    ngx = norm(gx)
  end
  return x, fx, ngx
end
</code></pre><p>And we run in the problems with</p><pre tabindex=0><code>newton(adnlp)
newton(mpbnlp)
</code></pre><p><em>Write once, use on problems from different sources.</em></p><p>Now, to have more fun, let&rsquo;s get another package:
<a href=https://github.com/JuliaSmoothOptimizers/OptimizationProblems.jl>OptimizationProblems.jl</a>.
This package doesn&rsquo;t have a release yet, so we have to clone it:</p><pre tabindex=0><code>Pkg.clone(&#34;https://github.com/JuliaSmoothOptimizers/OptimizationProblems.jl&#34;)
</code></pre><p>What we have here is a collection of JuMP models implementing some of the
CUTEst problems. Together with <code>NLPModels.jl</code>, we have a good opportunity to test our Newton implementation.</p><pre tabindex=0><code>using OptimizationProblems

x, fx, ngx = newton(MathProgNLPModel( rosenbrock() ))
x, fx, ngx = newton(MathProgNLPModel( dixmaanj() ))
x, fx, ngx = newton(MathProgNLPModel( brownbs() ))
</code></pre><p><em>An issue with OptimizationProblems is that it still doesn&rsquo;t have a way to get
all unconstrained problems, for instance. (PRs are welcome).</em></p><p>So far we used 3 packages from JSO: <code>NLPModels.jl</code>, <code>LinearOperators.jl</code> and <code>OptimizationProblems.jl</code>. It&rsquo;s time to meet another important package.</p><p><strong>CUTEst.jl</strong></p><p>CUTEst, the Constrained and Unconstrained Testing Environment with safe
threads, is a package written in Fortran providing over a thousand problems to
allow testing of Nonlinear Programming solvers. However, CUTEst is hard to use
by first-timers. Just installing it was already hard.
CUTEst.jl provides an interface for CUTEst that is simple to install and use
(comparing to the original).</p><p><em>Obs.: CUTEst.jl does not work on Windows for now. In fact, there is no plan to
make it work on Windows because &ldquo;people interested in doing it"∩"people capable
of doing it&rdquo; = ∅, as far as we&rsquo;ve looked. If you are in this set, PRs are
welcome.</em></p><p>To install CUTEst.jl you need to install something manually. Unfortunately,
this is specific for each system. Except for OSX, actually, which is using
<a href=https://github.com/optimizers/homebrew-cutest>homebrew-cutest</a>.</p><p>For Linux users, check out <a href=http://juliasmoothoptimizers.github.io/CUTEst.jl/latest/#Installing-1>this
page</a>.
Essentially, we need <code>libgfortran.so</code> in a visible place. And it&rsquo;s especially
annoying that some distritions don&rsquo;t put it in a visible place.</p><p>With that done, enter</p><pre tabindex=0><code>Pkg.add(&#34;CUTEst&#34;)
</code></pre><p>which should install CUTEst.jl 0.1.0.</p><p>Yes, it takes some time.</p><p>Finally, we start using CUTEst with</p><pre tabindex=0><code>using CUTEst

nlp = CUTEstModel(&#34;ROSENBR&#34;)
</code></pre><p><code>ROSENBR</code> is a CUTEst problem, in case you want the list, see
<a href=http://www.cuter.rl.ac.uk/Problems/mastsif.html>here</a>. Keep reading for a way
to select them, though.</p><p>Now, let&rsquo;s solve this CUTEst problem with our Newton method.</p><pre tabindex=0><code>x, fx, ngx = newton(nlp)
</code></pre><p><strong>Yes, exactly like before!</strong>.</p><p>CUTEst is a little more annoying in other aspect also. Like, you can&rsquo;t have two
or more problems open at the same time, and you have to close this problem
before opening a new one. (Again, PRs are welcome).</p><pre tabindex=0><code>finalize(nlp)
nlp = CUTEstModel(&#34;HIMMELBB&#34;)
x, fx, ngx = newton(nlp)
finalize(nlp)
</code></pre><p>This allows a simple workflow for writing optimization solvers.</p><ul><li>Write some problems by hand (using <code>ADNLPModel</code> or <code>MathProgNLPModel</code>);</li><li>Test your solvers with these hand-written problems;</li><li>Repeat last two steps until you believe you&rsquo;re ready to competitive comparison;</li><li>Test with CUTEst problems seamlessly.</li></ul><p>Now, let&rsquo;s get back to <code>hess_op</code>. Remember that it used Matrix vector products?
Well, CUTEst has separate functions for the product of the Hessian at a point
and a vector. Which means that <code>hprod</code> actually computes this product without
having to create the matrix. Which means it is, at least, memory-efficient.
Furthermore, <code>hess_op</code> will be created with the <code>hprod</code> function, which means
it is also memory-efficient.</p><p>Let&rsquo;s look at a huge problem to feel the difference.</p><pre tabindex=0><code>nlp = CUTEstModel(&#34;BOX&#34;)
nlp.meta.nvar
</code></pre><p>Let&rsquo;s make a simple comparison</p><pre tabindex=0><code>function foo1()
  H = hess(nlp, nlp.meta.x0)
  v = ones(nlp.meta.nvar)
  return Hermitian(H, :L) * v
end

function foo2()
  H = hess_op(nlp, nlp.meta.x0)
  v = ones(nlp.meta.nvar)
  return H * v
end

@time w1 = foo1();
@time w2 = foo2();
norm(w1 - w2)
</code></pre><p>Yes, that&rsquo;s a huge difference.</p><p>This is a very good reason to use <code>hess_op</code> and <code>hprod</code>. But let&rsquo;s take a step further.</p><p>We can&rsquo;t implement Cholesky using only <code>hprod</code>s, so our Newton method would
actually take a long time to reach a solution for the problem above.
To circunvent that, we could try using the Conjugate Gradients Method instead
of Cholesky. This would only use Hessian-vector products.</p><p>We arrive on a new package,
<a href=https://github.com/JuliaSmoothOptimizers/Krylov.jl>Krylov.jl</a>, which
implements Krylov methods. In particular, Conjugate Gradients.
This package is also unreleased, so we need to clone it.</p><pre tabindex=0><code>Pkg.clone(&#34;https://github.com/JuliaSmoothOptimizers/Krylov.jl&#34;)
</code></pre><p>Consider a simple example</p><pre tabindex=0><code>using Krylov
A = rand(3,3)
A = A*A&#39;
b = A*ones(3)
cg(A, b)
</code></pre><p>As expected, the system is solver, and the solution is $(1,1,1)$.
But let&rsquo;s do something more.</p><pre tabindex=0><code>A = -A
cg(A, b)
</code></pre><p>Yes, Krylov does indeed solves the non-positive definite system using Conjugate Gradient.
Well, actually, a variant.</p><p>That&rsquo;s not enough tough. Krylov.jl also accepts an additional argument <code>radius</code>
to set a trust-region radius.</p><pre tabindex=0><code>cg(A, b, radius=0.1)
</code></pre><p>Well, as an exercise I suggest you implement a trust-region version of Newton
method, but for now, let&rsquo;s continue with our line-search version.</p><p>We know now how <code>cg</code> behaves for non-positive definite systems, we can&rsquo;t make
the changes for a new method.</p><pre tabindex=0><code>function newton2(nlp :: AbstractNLPModel)
  x = nlp.meta.x0
  fx = obj(nlp, x)
  gx = grad(nlp, x)
  ngx = norm(gx)
  while norm(gx) &gt; 1e-6
    Hx = hess_op(nlp, x)
    d, _ = cg(Hx, -gx)
    slope = dot(gx, d)
    if slope &gt;= 0 # Not a descent direction
      d = -gx
      slope = -dot(d,d)
    end
    t = 1.0
    xt = x + t * d
    ft = obj(nlp, xt)
    while ft &gt; fx + 0.5 * t * slope
      t *= 0.5
      xt = x + t * d
      ft = obj(nlp, xt)
    end
    x = xt
    fx = ft
    gx = grad(nlp, x)
    ngx = norm(gx)
  end
  return x, fx, ngx
end
</code></pre><p>Now, running <code>newton2</code> on our large problem, we obtain</p><pre tabindex=0><code>x, fx, ngx = newton2(nlp)
</code></pre><p>Which is the method working very fast. Less that a second here.</p><hr><p>There is actually another package I&rsquo;d like to talk about, but it needs some
more work for it to be ready for a release:</p><p><strong>Optimize.jl</strong></p><p>Optimize.jl is a package with solvers. We intend to implement some high quality
solvers in there, but there is actually more to it. We have in there tools to
benchmark packages. These tools should allow the testing of a set of solvers in
a set of problems without much fuss, while creating the comparison information,
including the performance profile.
It also includes, or will include, &ldquo;parts&rdquo; of solvers to create your own
solver. Like trust-region and line-search algorithms and auxiliary functions
and types.
Unfortunately, it&rsquo;s not done enough for me to extend on it, and this is already
getting too long.</p><p><strong>End</strong></p><p>I hope you enjoyed this overview of packages.
Subscribe to the RSS feed to keep updated in future tutorials. I intend to talk
about the constrained part of NLPModels soon.</p><ul class=pa0><li class="list di"><a href=/tags/julia/ class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">julia</a></li><li class="list di"><a href=/tags/optimization/ class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">optimization</a></li><li class="list di"><a href=/tags/nlpmodels/ class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">nlpmodels</a></li><li class="list di"><a href=/tags/cutest/ class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">cutest</a></li><li class="list di"><a href=/tags/work/ class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">work</a></li><li class="list di"><a href=/tags/juliasmoothoptimizers/ class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">juliasmoothoptimizers</a></li><li class="list di"><a href=/tags/tutorial/ class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">tutorial</a></li></ul><div class="mt6 instapaper_ignoref"></div></div><aside class="w-30-l mt6-l"><div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links"><p class="f5 b mb3">Related</p><ul class="pa0 list"><li class=mb2><a href=/blog/2016-02-28-minicurso-de-julia-para-otimizacao/>Minicurso de Julia para Otimização</a></li><li class=mb2><a href=/blog/2016-11-29-smne-2016-julia/>Apresentação de Julia no SMNE</a></li><li class=mb2><a href=/blog/2016-02-14-viii-simposio-de-analise-numerica/>VIII Simpósio de Análise Numérica e Otimização - Minicurso de Julia</a></li><li class=mb2><a href=/blog/2015-10-01-installing-cutest-and-cutestjl/>Installing CUTEst and CUTEst.jl</a></li><li class=mb2><a href=/blog/2015-02-25-apresentacao-no-vii-simposio-de-analise-numerica-e-otimizacao-ufpr/>Apresentação no VII Simpósio de Análise Numérica e Otimização - UFPR</a></li><li class=mb2><a href=/blog/2015-02-06-cutestjl/>CUTEst.jl</a></li><li class=mb2><a href=/blog/2015-01-22-a-study-in-julia/>A Study in Julia</a></li><li class=mb2><a href=/blog/2017-01-15-julia-fractal-on-julia/>Julia Fractal on Julia</a></li><li class=mb2><a href=/blog/2016-12-18-advent-of-code-2016-in-julia/>Advent of Code 2016 in Julia</a></li><li class=mb2><a href=/blog/2016-08-21-a-quasi-solution-to-my-bib-problem/>A quasi-solution to my bib problem</a></li><li class=mb2><a href=/blog/2016-03-13-test-driven-development-in-julia/>Test Driven Development in Julia</a></li><li class=mb2><a href=/blog/2016-02-23-ubuntu-graphic-interface-stopped-working/>Ubuntu graphic interface stopped working</a></li><li class=mb2><a href=/blog/2016-02-21-automated-testing/>Automated testing</a></li><li class=mb2><a href=/blog/2015-11-20-apresentacao-no-poincare---2015/>Apresentação no Poincaré - 2015</a></li><li class=mb2><a href=/blog/2015-11-16-new-computer-at-work/>New computer at work</a></li></ul></div></aside></article></main><footer class="bg-dark-blue bottom-0 w-100 pa3" role=contentinfo><div class="flex justify-between"><a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href=https://abelsiqueira.com/>&copy; Abel Soares Siqueira 2022</a><div><div class=ananke-socials><a href=https://twitter.com/abel_siqueira target=_blank rel=noopener class="twitter ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="Twitter link" aria-label="follow on Twitter——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167 22.283c-2.619.953-4.274 3.411-4.086 6.101l.063 1.038-1.048-.127c-3.813-.487-7.145-2.139-9.974-4.915l-1.383-1.377-.356 1.017c-.754 2.267-.272 4.661 1.299 6.271.838.89.649 1.017-.796.487-.503-.169-.943-.296-.985-.233-.146.149.356 2.076.754 2.839.545 1.06 1.655 2.097 2.871 2.712l1.027.487-1.215.021c-1.173.0-1.215.021-1.089.467.419 1.377 2.074 2.839 3.918 3.475l1.299.444-1.131.678c-1.676.976-3.646 1.526-5.616 1.568C19.775 43.256 19 43.341 19 43.405c0 .211 2.557 1.397 4.044 1.864 4.463 1.377 9.765.783 13.746-1.568 2.829-1.673 5.657-5 6.978-8.221.713-1.716 1.425-4.851 1.425-6.354.0-.975.063-1.102 1.236-2.267.692-.678 1.341-1.419 1.467-1.631.21-.403.188-.403-.88-.043-1.781.636-2.033.551-1.152-.402.649-.678 1.425-1.907 1.425-2.267.0-.063-.314.042-.671.233-.377.212-1.215.53-1.844.72l-1.131.361-1.027-.7c-.566-.381-1.361-.805-1.781-.932C39.766 21.902 38.131 21.944 37.167 22.283zM33 64C16.432 64 3 50.569 3 34S16.432 4 33 4s30 13.431 30 30S49.568 64 33 64z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span></a><a href=https://github.com/abelsiqueira target=_blank rel=noopener class="github ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="GitHub link" aria-label="follow on GitHub——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 512 512" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M256 32C132.3 32 32 134.8 32 261.7c0 101.5 64.2 187.5 153.2 217.9 11.2 2.1 15.3-5 15.3-11.1.0-5.5-.2-19.9-.3-39.1-62.3 13.9-75.5-30.8-75.5-30.8-10.2-26.5-24.9-33.6-24.9-33.6-20.3-14.3 1.5-14 1.5-14 22.5 1.6 34.3 23.7 34.3 23.7 20 35.1 52.4 25 65.2 19.1 2-14.8 7.8-25 14.2-30.7-49.7-5.8-102-25.5-102-113.5.0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8.0.0 18.8-6.2 61.6 23.5 17.9-5.1 37-7.6 56.1-7.7 19 .1 38.2 2.6 56.1 7.7 42.8-29.7 61.5-23.5 61.5-23.5 12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6.0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5.0 30.7-.3 55.5-.3 63 0 6.1 4 13.3 15.4 11C415.9 449.1 480 363.1 480 261.7 480 134.8 379.7 32 256 32z"/></svg></span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span></a><a href=https://linkedin.com/in/abel-siqueira target=_blank rel=noopener class="linkedin ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" aria-label="follow on LinkedIn——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 65 65" viewBox="0 0 65 65" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M50.837 48.137V36.425c0-6.275-3.35-9.195-7.816-9.195-3.604.0-5.219 1.983-6.119 3.374V27.71h-6.79c.09 1.917.0 20.427.0 20.427h6.79V36.729c0-.609.044-1.219.224-1.655.49-1.22 1.607-2.483 3.482-2.483 2.458.0 3.44 1.873 3.44 4.618v10.929H50.837zM22.959 24.922c2.367.0 3.842-1.57 3.842-3.531-.044-2.003-1.475-3.528-3.797-3.528s-3.841 1.524-3.841 3.528c0 1.961 1.474 3.531 3.753 3.531H22.959zM34 64C17.432 64 4 50.568 4 34 4 17.431 17.432 4 34 4s30 13.431 30 30c0 16.568-13.432 30-30 30zM26.354 48.137V27.71h-6.789v20.427h6.789z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span></a><a href=https://mathstodon.xyz/@abelsiqueira target=_blank rel="me noopener" class="mastodon ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="Mastodon link" aria-label="follow on Mastodon——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" xmlns="http://www.w3.org/2000/svg"><path d="M61.731833 16.783448C60.855064 10.336694 55.17491 5.2562169 48.441526 4.2717554 47.305526 4.1054038 43.001372 3.5 33.030833 3.5h-.07446c-9.973232.0-12.112924.6054038-13.248924.7717554C13.161526 5.2289477 7.1836569 9.7940169 5.7332999 16.317063c-.6976035 3.212462-.7720515 6.774-.6424569 10.041.1847407 4.685077.2205861 9.361923.6507292 14.027923.2973693 3.099385.8161231 6.174077 1.552377 9.201 1.3786615 5.590462 6.9594998 10.242769 12.4272688 12.140846 5.854077 1.979385 12.149615 2.307923 18.181846.949.663539-.152692 1.319846-.33 1.968693-.531769 1.464153-.460846 3.182-.976308 4.444846-1.881692.01731-.01269.03154-.02908.04154-.048.01-.01885.01562-.03977.01631-.06108v-4.521385c-308e-6-.01992-.0051-.03954-.014-.05738-.009-.01785-.02185-.03354-.03777-.04577-.01585-.01231-.03431-.02092-.05392-.02531-.01969-.0043-.04008-.0042-.05969 23e-5-3.864769.913077-7.825154 1.370769-11.798615 1.363539-6.838154.0-8.677308-3.209693-9.204-4.546-.423308-1.154846-.692154-2.359462-.799615-3.583308-.0011-.02054.0028-.04108.01115-.05992.0084-.01877.02123-.03538.03731-.04839.01615-.013.03515-.02208.05546-.02646.02031-.0045.04138-.004.06154.0012 3.800385.906846 7.696154 1.364538 11.605615 1.363538.940231.0 1.877693.0 2.818-.02454 3.931923-.109077 8.076154-.308154 11.944693-1.055385.09654-.01908.193-.03546.275769-.06 6.101923-1.159 11.908846-4.796846 12.498923-14.008846.02208-.362692.07723-3.798769.07723-4.175077.0028-1.279.416384-9.072846-.06069-13.861538zm-9.391461 22.98623H45.924141V24.225525c0-3.272462-1.378692-4.941385-4.182923-4.941385-3.082692.0-4.626769 1.974385-4.626769 5.874v8.508385H30.736757V25.15814c0-3.899615-1.546847-5.874-4.629539-5.874-2.787692.0-4.180154 1.668923-4.182923 4.941385V39.769678H15.513526V23.753755c0-3.272461.844692-5.87223 2.534-7.799384 1.742615-1.922539 4.028461-2.909693 6.865769-2.909693 3.283923.0 5.765538 1.248923 7.419923 3.744231l1.596539 2.650692 1.59923-2.650692c1.654385-2.495308 4.136-3.744231 7.414462-3.744231 2.834538.0 5.120308.987154 6.868461 2.909693 1.689385 1.925307 2.534 4.525077 2.534 7.799384z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span></a><a href=https://instagram.com/siqueiraabel target=_blank rel=noopener class="instagram ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="Instagram link" aria-label="follow on Instagram——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M42.271 26.578v-.006c.502.0 1.005.01 1.508-.002.646-.017 1.172-.57 1.172-1.217.0-.963.0-1.927.0-2.89.0-.691-.547-1.24-1.236-1.241-.961.0-1.922-.001-2.883.0-.688.001-1.236.552-1.236 1.243-.001.955-.004 1.91.003 2.865.001.143.028.291.073.426.173.508.639.82 1.209.823C41.344 26.579 41.808 26.578 42.271 26.578zM33 27.817c-3.384-.002-6.135 2.721-6.182 6.089-.049 3.46 2.72 6.201 6.04 6.272 3.454.074 6.248-2.686 6.321-6.043C39.254 30.675 36.462 27.815 33 27.817zM21.046 31.116v.082c0 4.515-.001 9.03.0 13.545.0.649.562 1.208 1.212 1.208 7.16.001 14.319.001 21.479.0.656.0 1.215-.557 1.215-1.212.001-4.509.0-9.02.0-13.528v-.094H42.04c.411 1.313.537 2.651.376 4.014s-.601 2.631-1.316 3.803-1.644 2.145-2.779 2.918c-2.944 2.006-6.821 2.182-9.946.428-1.579-.885-2.819-2.12-3.685-3.713-1.289-2.373-1.495-4.865-.739-7.451C22.983 31.116 22.021 31.116 21.046 31.116zM45.205 49.255c.159-.026.318-.049.475-.083 1.246-.265 2.264-1.304 2.508-2.557.025-.137.045-.273.067-.409V21.794c-.021-.133-.04-.268-.065-.401-.268-1.367-1.396-2.428-2.78-2.618-.058-.007-.113-.02-.17-.03H20.761c-.147.027-.296.047-.441.08-1.352.308-2.352 1.396-2.545 2.766-.008.057-.02.114-.029.171V46.24c.028.154.05.311.085.465.299 1.322 1.427 2.347 2.77 2.52.064.008.13.021.195.03H45.205zM33 64C16.432 64 3 50.569 3 34S16.432 4 33 4s30 13.431 30 30S49.568 64 33 64z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span></a><a href=https://youtube.com/@abelsiqueira target=_blank rel=noopener class="youtube ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="YouTube link" aria-label="follow on YouTube——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M42.527 41.34c-.278.0-.478.078-.6.244-.121.156-.18.424-.18.796v.896h1.543V42.38c0-.372-.062-.64-.185-.796C42.989 41.418 42.792 41.34 42.527 41.34zM36.509 41.309c.234.0.417.076.544.23.123.155.185.383.185.682v4.584c0 .286-.053.487-.153.611-.1.127-.256.189-.47.189-.148.0-.287-.033-.421-.096-.135-.062-.274-.171-.415-.313v-5.531c.119-.122.239-.213.36-.271C36.26 41.335 36.383 41.309 36.509 41.309zm5.239 3.349v1.672c0 .468.057.792.17.974.118.181.313.269.592.269.289.0.491-.076.606-.229.114-.153.175-.489.175-1.013v-.405h1.795v.456c0 .911-.217 1.596-.657 2.059-.435.459-1.089.687-1.958.687-.781.0-1.398-.242-1.847-.731-.448-.486-.676-1.157-.676-2.014v-3.986c0-.768.249-1.398.742-1.882.493-.484 1.128-.727 1.911-.727.799.0 1.413.225 1.843.674.429.448.642 1.093.642 1.935v2.264H41.748zm-3.125 3.837c-.271.336-.669.501-1.187.501-.343.0-.646-.062-.912-.192-.267-.129-.519-.327-.746-.601v.681h-1.764V36.852h1.764v3.875c.237-.27.485-.478.748-.616.267-.143.534-.212.805-.212.554.0.975.189 1.265.565.294.379.438.933.438 1.66v4.926C39.034 47.678 38.897 48.159 38.623 48.495zM30.958 48.884v-.976c-.325.361-.658.636-1.009.822-.349.191-.686.282-1.014.282-.405.0-.705-.129-.913-.396-.201-.266-.305-.658-.305-1.189v-7.422h1.744v6.809c0 .211.037.362.107.457.077.095.196.141.358.141.128.0.292-.062.488-.188.197-.125.375-.283.542-.475v-6.744H32.7v8.878H30.958zM24.916 38.6v10.284h-1.968V38.6h-2.034v-1.748h6.036V38.6H24.916zm8.078-5.622c0-.001 12.08.018 13.514 1.45 1.439 1.435 1.455 8.514 1.455 8.555.0.0-.012 7.117-1.455 8.556C45.074 52.969 32.994 53 32.994 53s-12.079-.031-13.516-1.462c-1.438-1.435-1.441-8.502-1.441-8.556.0-.041.004-7.12 1.441-8.555 1.438-1.431 13.516-1.45 13.516-1.449zm9.526-3.723h-1.966v-1.08c-.358.397-.736.703-1.13.909-.392.208-.771.312-1.14.312-.458.0-.797-.146-1.027-.437-.229-.291-.345-.727-.345-1.311v-8.172h1.962v7.497c0 .231.045.399.127.502.08.104.216.156.399.156.143.0.327-.069.548-.206.22-.137.423-.312.605-.527v-7.422h1.966V29.255zM31.847 27.588c.139.147.339.219.6.219.266.0.476-.075.634-.223.157-.152.235-.358.235-.618v-5.327c0-.214-.08-.387-.241-.519-.16-.131-.37-.196-.628-.196-.241.0-.435.065-.586.196-.148.132-.225.305-.225.519v5.327C31.636 27.233 31.708 27.439 31.847 27.588zm-1.439-7.685c.528-.449 1.241-.674 2.132-.674.812.0 1.48.237 2.001.711.517.473.777 1.083.777 1.828v5.051c0 .836-.255 1.491-.762 1.968-.513.476-1.212.714-2.106.714-.858.0-1.547-.246-2.064-.736-.513-.492-.772-1.152-.772-1.983v-5.068C29.613 20.954 29.877 20.351 30.408 19.903zM24.262 16h-2.229l2.634 8.003v5.252h2.213v-5.5L29.454 16h-2.25l-1.366 5.298h-.139L24.262 16zM33 64C16.432 64 3 50.569 3 34S16.432 4 33 4s30 13.431 30 30S49.568 64 33 64z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span></a></div></div></div></footer></body></html>