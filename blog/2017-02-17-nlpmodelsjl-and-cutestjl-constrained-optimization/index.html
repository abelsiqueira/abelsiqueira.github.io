<!doctype html><html><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><meta http-equiv=accept-ch content="DPR, Viewport-Width, Width"><link rel=icon href=/images/icon.png type=image/gif><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Alata&family=Lora:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Alata&family=Lora:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" media=print onload='this.media="all"'><noscript><link href="https://fonts.googleapis.com/css2?family=Alata&family=Lora:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" rel=stylesheet></noscript><link rel=stylesheet href=/css/font.css media=all><script async src="https://www.googletagmanager.com/gtag/js?id=G-WS6K0SDB05"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-WS6K0SDB05",{anonymize_ip:!1})}</script><meta property="og:title" content="NLPModels.jl and CUTEst.jl: Constrained optimization"><meta property="og:description" content="This is a continuation of this post. And again, you can follow the commands of this post in the asciinema.
If you followed along last post, you should know the basics of our NLPModels API, including CUTEst access.
One thing I didn&rsquo;t explore, though, was constrained problems. It&rsquo;d complicate too much.
However, now that we know how to handle the basics, we can move to the advanced.
Nonlinear Programming format"><meta property="og:type" content="article"><meta property="og:url" content="https://abelsiqueira.com/blog/2017-02-17-nlpmodelsjl-and-cutestjl-constrained-optimization/"><meta property="article:section" content="blog"><meta property="article:published_time" content="2017-02-17T00:00:00+00:00"><meta property="article:modified_time" content="2017-02-17T00:00:00+00:00"><meta property="og:site_name" content="Abel Soares Siqueira"><meta name=twitter:card content="summary"><meta name=twitter:title content="NLPModels.jl and CUTEst.jl: Constrained optimization"><meta name=twitter:description content="This is a continuation of this post. And again, you can follow the commands of this post in the asciinema.
If you followed along last post, you should know the basics of our NLPModels API, including CUTEst access.
One thing I didn&rsquo;t explore, though, was constrained problems. It&rsquo;d complicate too much.
However, now that we know how to handle the basics, we can move to the advanced.
Nonlinear Programming format"><link rel=stylesheet href=/bootstrap-5/css/bootstrap.min.css media=all><link rel=stylesheet href=/css/header.css media=all><link rel=stylesheet href=/css/footer.css media=all><link rel=stylesheet href=/css/theme.css media=all><link rel=stylesheet href=/style.css><style>:root{--text-color:#343a40;--text-secondary-color:#6c757d;--background-color:#eaedf0;--secondary-background-color:#64ffda1a;--primary-color:#007bff;--secondary-color:#f8f9fa;--text-color-dark:#e4e6eb;--text-secondary-color-dark:#b0b3b8;--background-color-dark:#18191a;--secondary-background-color-dark:#212529;--primary-color-dark:#ffffff;--secondary-color-dark:#212529}body{font-size:1rem;font-weight:400;line-height:1.5;text-align:left}html{background-color:var(--background-color)!important}body::-webkit-scrollbar{width:.5em;height:.5em;background-color:var(--background-color)}::-webkit-scrollbar-track{box-shadow:inset 0 0 6px var(--background-color);border-radius:1rem}::-webkit-scrollbar-thumb{border-radius:1rem;background-color:var(--secondary-color);outline:1px solid var(--background-color)}#search-content::-webkit-scrollbar{width:.5em;height:.1em;background-color:var(--background-color)}</style><meta name=description content><link rel=stylesheet href=/css/single.css><script defer src=/fontawesome-5/all-5.15.4.js></script><title>NLPModels.jl and CUTEst.jl: Constrained optimization | Abel Soares Siqueira</title></head><body class=light><script>let localStorageValue=localStorage.getItem("pref-theme"),mediaQuery=window.matchMedia("(prefers-color-scheme: dark)").matches;switch(localStorageValue){case"dark":document.body.classList.add("dark");break;case"light":document.body.classList.remove("dark");break;default:mediaQuery&&document.body.classList.add("dark");break}</script><header><nav class="pt-3 navbar navbar-expand-lg animate"><div class="container-fluid mx-xs-2 mx-sm-5 mx-md-5 mx-lg-5"><a class="navbar-brand primary-font text-wrap" href=/>Abel Soares Siqueira</a><div><input id=search autocomplete=off class="form-control mr-sm-2 d-none d-md-block" placeholder='Ctrl + k to Search...' aria-label=Search oninput=searchOnChange(event)></div><button class=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#navbarContent aria-controls=navbarContent aria-expanded=false aria-label="Toggle navigation"><svg aria-hidden="true" height="24" viewBox="0 0 16 16" width="24" data-view-component="true"><path fill-rule="evenodd" d="M1 2.75A.75.75.0 011.75 2h12.5a.75.75.0 110 1.5H1.75A.75.75.0 011 2.75zm0 5A.75.75.0 011.75 7h12.5a.75.75.0 110 1.5H1.75A.75.75.0 011 7.75zM1.75 12a.75.75.0 100 1.5h12.5a.75.75.0 100-1.5H1.75z"/></svg></button><div class="collapse navbar-collapse text-wrap primary-font" id=navbarContent><ul class="navbar-nav ms-auto text-center"><li class="nav-item navbar-text d-block d-md-none"><div class=nav-link><input id=search autocomplete=off class="form-control mr-sm-2" placeholder='Ctrl + k to Search...' aria-label=Search oninput=searchOnChange(event)></div></li><li class="nav-item navbar-text"><a class=nav-link href=/#about aria-label=about>About Me</a></li><li class="nav-item navbar-text"><a class=nav-link href=/#experience aria-label=experience>Experience</a></li><li class="nav-item navbar-text"><a class=nav-link href=/#education aria-label=education>Education</a></li><li class="nav-item navbar-text"><a class=nav-link href=/#projects aria-label=projects>Projects</a></li><li class="nav-item navbar-text"><a class=nav-link href=/#contact aria-label=contact>Contact</a></li><li class="nav-item navbar-text"><a class=nav-link href=/blog title="Blog posts">Blog</a></li><li class="nav-item navbar-text"><a class=nav-link href=/cv title=Curriculum>Curriculum</a></li><li class="nav-item navbar-text"><div class=text-center><button id=theme-toggle><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></li></ul></div></div></nav></header><div id=content><section id=single><div class=container><div class="row justify-content-center"><div class="col-sm-12 col-md-12 col-lg-9"><div class=pr-lg-4><div class="title mb-5"><h1 class="text-center mb-4">NLPModels.jl and CUTEst.jl: Constrained optimization</h1><div class=text-center><small>|</small>
Feb 17, 2017
<span id=readingTime>min read</span></div></div><article class="page-content p-2"><p>This is a continuation of <a href=https://abelsiqueira.github.io%7B%7Blocal_prefix%7D%7Dnlpmodelsjl-cutestjl-and-other-nonlinear-optimization-packages-on-julia/>this
post</a>.
And again, you can follow the commands of this post in the
<a href=https://asciinema.org/a/103654>asciinema</a>.</p><p>If you followed along last post, you should know the basics of our
NLPModels API, including CUTEst access.</p><p>One thing I didn&rsquo;t explore, though, was constrained problems.
It&rsquo;d complicate too much.</p><p>However, now that we know how to handle the basics, we can move to the
advanced.</p><p><strong>Nonlinear Programming format</strong></p><p>The NLPModels internal structure is based on the CUTEst way of storing a
problem.
We use the following form for the optimization problem:</p><p>$$
\begin{align}
\min \quad & f(x) \
s.t. \quad & c_L \leq c(x) \leq c_U \
& \ell \leq x \leq u\end{align}
$$</p><p>Given an <code>AbstractNLPModel</code> named <code>nlp</code>, the values for $\ell$, $u$, $c_L$ and
$c_U$ are stored in an <code>NLPModelMeta</code> structure, and can be accessed by
through <code>nlp.meta</code>.</p><p>Let&rsquo;s look back at the simple Rosenbrock problem of before.</p><pre tabindex=0><code>using NLPModels

f(x) = (x[1] - 1)^2 + 100*(x[2] - x[1]^2)^2
x0 = [-1.2; 1.0]
nlp = ADNLPModel(f, x0)
print(nlp.meta)
</code></pre><p>You should be seeing this:</p><pre tabindex=0><code>Minimization problem Generic
nvar = 2, ncon = 0 (0 linear)
lvar = -Inf  -Inf
uvar = Inf  Inf
lcon = ∅
ucon = ∅
x0 = -1.2  1.0
y0 = ∅
nnzh = 4
nnzj = 0
</code></pre><p>Although the meaning of these values is reasonably straigthforward, I&rsquo;ll explain a bit.</p><ul><li><code>nvar</code> is the number of variables in a problem;</li><li><code>ncon</code> is the number of constraints, without counting the bounds;</li><li><code>lvar</code> is the vector $\ell$, the lower bounds on the variables;</li><li><code>uvar</code> is the vector $u$, the upper bounds on the variables;</li><li><code>lcon</code> is the vector $c_L$, the lower bounds of the constraints function;</li><li><code>ucon</code> is the vector $c_U$, the upper bounds of the constraints function;</li><li><code>x0</code> is the initial approximation to the solution, aka the starting point;</li><li><code>y0</code> is the initial approximation to the Lagrange multipliers;</li><li><code>nnzh</code> is the number of nonzeros on the Hessian¹;</li><li><code>nnzj</code> is the number of nonzeros on the Jacobian¹;</li></ul><p><em>¹ <code>nnzh</code> and <code>nnzj</code> are not consistent between models, because some consider the dense matrix, and for the Hessian, some consider only the triangle. However, if you&rsquo;re possibly considering using <code>nnzh</code>, you&rsquo;re probably looking for <code>hess_coord</code> too, and <code>hess_coord</code> returns with the correct size.</em></p><p>These values can be accessed directly as fields in <code>meta</code> with the same name above.</p><pre tabindex=0><code>nlp.meta.ncon
nlp.meta.x0
nlp.meta.lvar
</code></pre><p><strong>Bounds</strong></p><p>Now, let&rsquo;s create a bounded problem.</p><pre tabindex=0><code>nlp = ADNLPModel(f, x0, lvar=zeros(2), uvar=[0.4; 0.6])
print(nlp.meta)
</code></pre><p>Now the bounds are set, and you can access them with</p><pre tabindex=0><code>nlp.meta.lvar
nlp.meta.uvar
</code></pre><p>That&rsquo;s pretty much it. For <code>SimpleNLPModel</code>, it&rsquo;s the same thing.
<code>MathProgNLPModel</code> inherits the bounds, as expected:</p><pre tabindex=0><code>using JuMP

jmp = Model()
u = [0.4; 0.6]
@variable(jmp, 0 &lt;= x[i=1:2] &lt;= u[i], start=(x0[i]))
@NLobjective(jmp, Min, (x[1] - 1)^2 + 100*(x[2] - x[1]^2)^2)
mpbnlp = MathProgNLPModel(jmp)
print(mpbnlp.meta)
</code></pre><p>For CUTEst, there is no differentiation on creating a problem with bounds or
not, since it uses the internal description of the problem.
For instance, <code>HS4</code> is a bounded problem.</p><pre tabindex=0><code>using CUTEst

clp = CUTEstModel(&#34;HS4&#34;)
print(clp.meta)
finalize(clp)
</code></pre><p>Notice that it can happen that one or more of the variables is unlimited
(lower, upper or both). This is represented by the value <code>Inf</code> in Julia.
This should be expected since the unconstrained problem already used these
<code>Inf</code> values.</p><p>On the other hand, it could happen that $\ell_i = u_i$, in which case the
variable is fixed, or that $\ell_i > u_i$, in which case the variable (and the
problem) is infeasible.
Note that <code>NLPModels</code> only creates the model, it doesn&rsquo;t check whether it is
feasible or not, even in this simple example. That said, CUTEst shouldn&rsquo;t have
any infeasible variable.</p><p>Furthermore, all these types of bounds can be accessed from <code>meta</code>. Notice that
there are 6 possible situations:</p><ul><li>Free variables, stored in <code>meta.ifree</code>;</li><li>Fixed variables, stored in <code>meta.ifix</code>;</li><li>Variables bounded below, stored in <code>meta.ilow</code>;</li><li>Variables bounded above, stored in <code>meta.iupp</code>;</li><li>Variables bounded above and below, stored in <code>meta.irng</code>;</li><li>Infeasible variables, stored in <code>meta.iinf</code>.</li></ul><p>Here is one example with one of each of them</p><pre tabindex=0><code>nlp = ADNLPModel(x-&gt;dot(x,x), zeros(6),
  lvar = [-Inf, -Inf, 0.0, 0.0, 0.0,  0.0],
  uvar = [ Inf,  1.0, Inf, 1.0, 0.0, -1.0])
nlp.meta.ifree
nlp.meta.ifix
nlp.meta.ilow
nlp.meta.iupp
nlp.meta.irng
nlp.meta.iinf
</code></pre><p><strong>Constraints</strong></p><p>Constraints are stored in NLPModels following in the format $c_L \leq c(x) \leq c_U$.
That means that an equality constraint happens when $c_{L_j} = c_{U_j}$.
Let&rsquo;s look at how to create a problem with constraints.</p><p>For <code>ADNLPModel</code>, you need to pass three keywords arguments: <code>c</code>, <code>lcon</code> and <code>ucon</code>,
which represent $c(x)$, $c_L$ and $c_U$, respectively.
For instance, the problem</p><p>$$
\begin{align}
\min \quad & x_1^2 + x_2^2 \
s.t. \quad & x_1 + x_2 = 1
\end{align}
$$</p><p>is created by doing</p><pre tabindex=0><code>c(x) = [x[1] + x[2] - 1]
lcon = [0.0]
ucon = [0.0]
nlp = ADNLPModel(x-&gt;dot(x,x), zeros(2), c=c, lcon=lcon, ucon=ucon)
</code></pre><p>or alternatively, if you don&rsquo;t want the intermediary functions</p><pre tabindex=0><code>nlp = ADNLPModel(x-&gt;dot(x,x), zeros(2), c=x-&gt;[x[1]+x[2]-1], lcon=[0.0], ucon=[0.0])
</code></pre><p>Another possibility is to do</p><pre tabindex=0><code>nlp = ADNLPModel(x-&gt;dot(x,x), zeros(2), c=x-&gt;[x[1]+x[2]], lcon=[1.0], ucon=[1.0])
</code></pre><p>Personally, I prefer the former.</p><p>For inequalities, you can have only lower, only upper, and both.
The commands</p><pre tabindex=0><code>nlp = ADNLPModel(x-&gt;dot(x,x), zeros(2),
  c=x-&gt;[x[1] + x[2]; 3x[1] + 2x[2]; x[1]*x[2]],
  lcon = [-1.0; -Inf; 1.0],
  ucon = [Inf;   3.0; 2.0])
</code></pre><p>implement the problem</p><p>$$
\begin{align}
\min \quad & x_1^2 + x_2^2 \
s.t. \quad & x_1 + x_2 \geq -1 \
& 3x_1 + 2x_2 \leq 3 \
& 1 \leq x_1x_2 \leq 2.
\end{align}
$$</p><p>Again, the types of constraints can be accessed in <code>meta</code>, through
<code>nlp.meta.jfix</code>, <code>jfree</code>, <code>jinf</code>, <code>jlow</code>, <code>jrng</code> and <code>jupp</code>.
Notice if you forget to set <code>lcon</code> and <code>ucon</code>, there will be no
constraints, even though <code>c</code> is set. This is because the number of
constraints is taken from the lenght of these vectors.</p><p>Now, to access these constraints, let&rsquo;s consider this simple problem.</p><pre tabindex=0><code>nlp = ADNLPModel(f, x0, c=x-&gt;[x[1]*x[2] - 0.5], lcon=[0.0], ucon=[0.0])
</code></pre><p>The function <code>cons</code> return $c(x)$.</p><pre tabindex=0><code>cons(nlp, nlp.meta.x0)
</code></pre><p>The function <code>jac</code> returns the Jacobian of $c$. <code>jprod</code> and <code>jtprod</code> the
Jacobian product times a vector, and <code>jac_op</code> the LinearOperator.</p><pre tabindex=0><code>jac(nlp, nlp.meta.x0)
jprod(nlp, nlp.meta.x0, ones(2))
jtprod(nlp, nlp.meta.x0, ones(1))
J = jac_op(nlp, nlp.meta.x0)
J * ones(2)
J&#39; * ones(1)
</code></pre><p>To get the Hessian we&rsquo;ll use the same functions as the unconstrained case,
with the addition of a keyword parameter <code>y</code>.</p><pre tabindex=0><code>y = [1e4]
hess(nlp, nlp.meta.x0, y=y)
hprod(nlp, nlp.meat.x0, ones(2))
H = hess_op(nlp, nlp.meta.x0, y=y)
H * ones(2)
</code></pre><p>If you want to ignore the objective function, or scale it by some value,
you can use the keyword parameter <code>obj_weight</code>.</p><pre tabindex=0><code>s = 0.0
hess(nlp, nlp.meta.x0, y=y, obj_weight=s)
hprod(nlp, nlp.meat.x0, ones(2), obj_weight=s)
H = hess_op(nlp, nlp.meta.x0, y=y, obj_weight=s)
H * ones(2)
</code></pre><p>Check the
<a href=http://juliasmoothoptimizers.github.io/NLPModels.jl/stable/api.html>API</a>
for more details.</p><p>We can also create a constrained JuMP model.</p><pre tabindex=0><code>x0 = [-1.2; 1.0]
jmp = Model()
@variable(jmp, x[i=1:2], start=(x0[i]))
@NLobjective(jmp, Min, (x[1] - 1)^2 + 100*(x[2] - x[1]^2)^2)
@NLcontraint(jmp, x[1]*x[2] == 0.5)
mpbnlp = MathProgNLPModel(jmp)
cons(mpbnlp, mpbnlp.meta.x0)
jac(mpbnlp, mpbnlp.meta.x0)
hess(mpbnlp, mpbnlp.meta.x0, y=y)
</code></pre><p>And again, the access in CUTEst problems is the same.</p><pre tabindex=0><code>clp = CUTEstModel(&#34;BT1&#34;)
cons(clp, clp.meta.x0)
jac(clp, clp.meta.x0)
hess(clp, clp.meta.x0, y=clp.meta.y0)
finalize(clp)
</code></pre><p><strong>Convenience functions</strong></p><p>There are some convenience functions to check whether a problem has only
equalities, only bounds, etc.
For clarification, we&rsquo;re gonna say function constraint to refer to constraints that are not bounds.</p><ul><li><code>has_bounds</code>: Returns <code>true</code> is variable has bounds.</li><li><code>bound_constrained</code>: Returns <code>true</code> if <code>has_bounds</code> and no function
constraints;</li><li><code>unconstrained</code>: No function constraints nor bounds;</li><li><code>linearly_constrained</code>: There are function constraints, and they are
linear; <em>obs: even though a <code>bound_constrained</code> problem is linearly
constrained, this will return false</em>.</li><li><code>equality_constrained</code>: There are function constraints, and they are all equalities;</li><li><code>inequality_constrained</code>: There are function constraints, and they are all inequalities;</li></ul><p><strong>Example solver</strong></p><p>Let&rsquo;s implement a &ldquo;simple&rdquo; solver for constrained optimization.
Our solver will loosely follow the Byrd-Omojokun implementation of</p><blockquote><p>M. Lalee, J. Nocedal, and T. Plantenga. <strong>On the implementation of an algorithm for large-scale equality constrained optimization</strong>. SIAM J. Optim., Vol. 8, No. 3, pp. 682-706, 1998.</p></blockquote><pre tabindex=0><code>function solver(nlp :: AbstractNLPModel)
  if !equality_constrained(nlp)
    error(&#34;This solver is for equality constrained problems&#34;)
  elseif has_bounds(nlp)
    error(&#34;Can&#39;t handle bounds&#34;)
  end

  x = nlp.meta.x0

  fx = obj(nlp, x)
  cx = cons(nlp, x)

  ∇fx = grad(nlp, x)
  Jx = jac_op(nlp, x)

  λ = cgls(Jx&#39;, -∇fx)[1]
  ∇ℓx = ∇fx + Jx&#39;*λ
  norm∇ℓx = norm(∇ℓx)

  Δ = max(0.1, min(100.0, 10norm∇ℓx))
  μ = 1
  v = zeros(nlp.meta.nvar)

  iter = 0
  while (norm∇ℓx &gt; 1e-4 || norm(cx) &gt; 1e-4) &amp;&amp; (iter &lt; 10000)
    # Vertical step
    if norm(cx) &gt; 1e-4
      v = cg(Jx&#39;*Jx, -Jx&#39;*cx, radius=0.8Δ)[1]
      Δp = sqrt(Δ^2 - dot(v,v))
    else
      fill!(v, 0)
      Δp = Δ
    end

    # Horizontal step
    # Simplified to consider only ∇ℓx = proj(∇f, Nu(A))
    B = hess_op(nlp, x, y=λ)
    B∇ℓx = B * ∇ℓx
    gtBg = dot(∇ℓx, B∇ℓx)
    gtγ = dot(∇ℓx, ∇fx + B * v)
    t = if gtBg &lt;= 0
      norm∇ℓx &gt; 0 ? Δp/norm∇ℓx : 0.0
    else
      t = min(gtγ/gtBg, Δp/norm∇ℓx)
    end

    d = v - t * ∇ℓx

    # Trial step acceptance
    xt = x + d
    ft = obj(nlp, xt)
    ct = cons(nlp, xt)
    γ = dot(d, ∇fx) + 0.5*dot(d, B * d)
    θ = norm(cx) - norm(Jx * d + cx)
    normλ = norm(λ, Inf)
    if θ &lt;= 0
      μ = normλ
    elseif normλ &gt; γ/θ
      μ = min(normλ, 0.1 + γ/θ)
    else
      μ = 0.1 + γ/θ
    end
    Pred = -γ + μ * θ
    Ared = fx - ft + μ * (norm(cx) - norm(ct))

    ρ = Ared/Pred
    if ρ &gt; 1e-2
      x .= xt
      fx = ft
      cx .= ct
      ∇fx = grad(nlp, x)
      Jx = jac_op(nlp, x)
      λ = cgls(Jx&#39;, -∇fx)[1]
      ∇ℓx = ∇fx + Jx&#39;*λ
      norm∇ℓx = norm(∇ℓx)
      if ρ &gt; 0.75 &amp;&amp; norm(d) &gt; 0.99Δ
        Δ *= 2.0
      end
    else
      Δ *= 0.5
    end

    iter += 1
  end

  return x, fx, norm∇ℓx, norm(cx)
end
</code></pre><p>Too loosely, in fact.</p><ul><li>The horizontal step computes only the Cauchy step;</li><li>No special updates;</li><li>No second-order correction;</li><li>No efficient implementation beyond the easy-to-do.</li></ul><p>To test how good it is, let&rsquo;s run on the Hock-Schittkowski constrained problems.</p><pre tabindex=0><code>function runcutest()
  problems = filter(x-&gt;contains(x, &#34;HS&#34;) &amp;&amp; length(x) &lt;= 5, CUTEst.select(only_free_var=true, only_equ_con=true))
  sort!(problems)
  @printf(&#34;%-7s  %15s  %15s  %15s\n&#34;,
          &#34;Problem&#34;, &#34;f(x)&#34;, &#34;‖∇ℓ(x,λ)‖&#34;, &#34;‖c(x)‖&#34;)
  for p in problems
    nlp = CUTEstModel(p)
    try
      x, fx, nlx, ncx = solver(nlp)
      @printf(&#34;%-7s  %15.8e  %15.8e  %15.8e\n&#34;, p, fx, nlx, ncx)
    catch
      @printf(&#34;%-7s  %s\n&#34;, p, &#34;failure&#34;)
    finally
      finalize(nlp)
    end
  end
end
</code></pre><p>I&rsquo;m gonna print the output of this one, so you can compare it with yours.</p><pre tabindex=0><code>Problem             f(x)        ‖∇ℓ(x,λ)‖           ‖c(x)‖
HS26      5.15931251e-07   9.88009545e-05   5.24359322e-05
HS27      4.00000164e-02   5.13264248e-05   2.26312672e-09
HS28      7.00144545e-09   9.46563681e-05   2.44249065e-15
HS39     -1.00000010e+00   1.99856691e-08   1.61607518e-07
HS40     -2.50011760e-01   4.52797064e-05   2.53246505e-05
HS42      1.38577292e+01   5.06661945e-05   5.33092868e-05
HS46      3.56533430e-06   9.98827045e-05   8.00086215e-05
HS47      3.53637757e-07   9.71339790e-05   7.70496596e-05
HS48      4.65110036e-10   4.85457139e-05   2.27798719e-15
HS49      3.14248189e-06   9.94899395e-05   2.27488138e-13
HS50      1.36244906e-12   2.16913725e-06   2.90632554e-14
HS51      1.58249170e-09   8.52213221e-05   6.52675179e-15
HS52      5.32664756e+00   3.35626559e-05   3.21155766e-14
HS56     -3.45604528e+00   9.91076239e-05   3.14471179e-05
HS6       5.93063756e-13   6.88804464e-07   9.61311292e-06
HS61     -1.43646176e+02   1.06116455e-05   1.80421875e-05
HS7      -1.73205088e+00   1.23808109e-11   2.60442422e-07
HS77      2.41501014e-01   8.31210333e-05   7.75367223e-05
HS78     -2.91972281e+00   2.27102179e-05   2.88776440e-05
HS79      7.87776482e-02   4.77319205e-05   7.55827729e-05
HS8      -1.00000000e+00   0.00000000e+00   2.39989802e-06
HS9      -5.00000000e-01   1.23438228e-06   3.55271368e-15
</code></pre><p>If you compare against the Hock-Schitkowski paper, you&rsquo;ll see that
the method converged for all 22 problems.
Considering our simplifications, this is a very exciting.</p><p>That&rsquo;s all for now. Use our RSS feed to keep updated.</p></article></div></div><div class="col-sm-12 col-md-12 col-lg-3"><div class=sticky-sidebar><aside class=toc><h5>Table Of Contents</h5><div class=toc-content><nav id=TableOfContents></nav></div></aside><aside class=tags><h5>Tags</h5><ul class="tags-ul list-unstyled list-inline"><li class=list-inline-item><a href=https://abelsiqueira.com/tags/julia target=_blank>julia</a></li><li class=list-inline-item><a href=https://abelsiqueira.com/tags/nlpmodels target=_blank>nlpmodels</a></li><li class=list-inline-item><a href=https://abelsiqueira.com/tags/cutest target=_blank>cutest</a></li><li class=list-inline-item><a href=https://abelsiqueira.com/tags/work target=_blank>work</a></li><li class=list-inline-item><a href=https://abelsiqueira.com/tags/optimization target=_blank>optimization</a></li><li class=list-inline-item><a href=https://abelsiqueira.com/tags/constrained target=_blank>constrained</a></li></ul></aside><aside class=social><h5>Social</h5><div class=social-content><ul class=list-inline><li class="list-inline-item text-center"><a target=_blank href="https://twitter.com/share?text=NLPModels.jl%20and%20CUTEst.jl%3a%20Constrained%20optimization&url=https%3a%2f%2fabelsiqueira.com%2fblog%2f2017-02-17-nlpmodelsjl-and-cutestjl-constrained-optimization%2f"><i class="fab fa-twitter"></i></a></li><li class="list-inline-item text-center"><a target=_blank href="https://api.whatsapp.com/send?text=NLPModels.jl%20and%20CUTEst.jl%3a%20Constrained%20optimization: https%3a%2f%2fabelsiqueira.com%2fblog%2f2017-02-17-nlpmodelsjl-and-cutestjl-constrained-optimization%2f"><i class="fab fa-whatsapp"></i></a></li><li class="list-inline-item text-center"><a target=_blank href='mailto:?subject=NLPModels.jl%20and%20CUTEst.jl%3a%20Constrained%20optimization&amp;body=Check%20out%20this%20site https%3a%2f%2fabelsiqueira.com%2fblog%2f2017-02-17-nlpmodelsjl-and-cutestjl-constrained-optimization%2f'><i class="fa fa-envelope"></i></a></li></ul></div></aside></div></div></div><div class=row><div class="col-sm-12 col-md-12 col-lg-9 p-4"></div></div></div><button class="p-2 px-3" onclick=topFunction() id=topScroll>
<i class="fas fa-angle-up"></i></button></section><div class=progress><div id=scroll-progress-bar class=progress-bar role=progressbar aria-valuenow=0 aria-valuemin=0 aria-valuemax=100></div></div><script src=/js/scrollProgressBar.js></script><script>var topScroll=document.getElementById("topScroll");window.onscroll=function(){scrollFunction()};function scrollFunction(){document.body.scrollTop>20||document.documentElement.scrollTop>20?topScroll.style.display="block":topScroll.style.display="none"}function topFunction(){document.body.scrollTop=0,document.documentElement.scrollTop=0}</script><script src=/js/readingTime.js></script></div><footer><div class="container py-3" id=recent-posts><div class="h3 text-center text-secondary py-3">Recent Posts</div><div class="row justify-content-center"><div class="col-lg-4 col-md-6 pt-2"><div class="card h-100"><div class=card-header><a href=/blog/2023-10-07-copiertemplate/><img src=/blog/2023-10-07/banner.jpg class=card-img-top alt="COPIERTemplate.jl: A new template for Julia using copier"></a></div><div class="card-body bg-transparent p-3 shadow-sm"><a href=/blog/2023-10-07-copiertemplate/ class="primary-font card-title"><h5 class="card-title bg-transparent" title="COPIERTemplate.jl: A new template for Julia using copier">COPIERTemplate.jl: A new …</h5></a><div class="card-text secondary-font"><p>I help manage over 50 packages in the Julia Smooth Optimizers organization, and sometimes we have to make a small update to all of these packages. For instance, one of the workflows was updated, or something new is introduced, or the LTS version of Julia changes.
In these situations, our usual …</p></div></div><div class="mt-auto card-footer"><span class=float-start>Oct 7, 2023</span>
<a href=/blog/2023-10-07-copiertemplate/ class="float-end btn btn-outline-info btn-sm">Read</a></div></div></div><div class="col-lg-4 col-md-6 pt-2"><div class="card h-100"><div class=card-header><a href=/blog/2023-09-05-best-frenemies-julia-and-python/><img src=/blog/2023-09-05/banner.gif class=card-img-top alt="Best Frenemies: Julia and Python"></a></div><div class="card-body bg-transparent p-3 shadow-sm"><a href=/blog/2023-09-05-best-frenemies-julia-and-python/ class="primary-font card-title"><h5 class="card-title bg-transparent" title="Best Frenemies: Julia and Python">Best Frenemies: Julia and …</h5></a><div class="card-text secondary-font"><p>Julia and Python are often seen as competitors, but in this video I want to show the integration between them. Using the PythonCall and the JuliaCall packages we can call Julia from Python and Python from Julia. Check the video out or check edited transcript below.
Don&rsquo;t forget to like and …</p></div></div><div class="mt-auto card-footer"><span class=float-start>Sep 5, 2023</span>
<a href=/blog/2023-09-05-best-frenemies-julia-and-python/ class="float-end btn btn-outline-info btn-sm">Read</a></div></div></div><div class="col-lg-4 col-md-6 pt-2"><div class="card h-100"><div class=card-header><a href=/blog/2023-08-30-julia-language-cannot-handle-simple-math/><img src=/blog/2023-08-30/banner.gif class=card-img-top alt="Julia Language Can't Even Handle Simple Math"></a></div><div class="card-body bg-transparent p-3 shadow-sm"><a href=/blog/2023-08-30-julia-language-cannot-handle-simple-math/ class="primary-font card-title"><h5 class="card-title bg-transparent" title="Julia Language Can't Even Handle Simple Math">Julia Language Can't Even …</h5></a><div class="card-text secondary-font"><p>I have a new video up about how Julia cannot even handle simple math! Check the video out or check an edited written version below.
Don&rsquo;t forget to like and subscribe
Introduction Julia is supposed to be a great programming language, but it can&rsquo;t even do simple math correctly. Take a …</p></div></div><div class="mt-auto card-footer"><span class=float-start>Aug 30, 2023</span>
<a href=/blog/2023-08-30-julia-language-cannot-handle-simple-math/ class="float-end btn btn-outline-info btn-sm">Read</a></div></div></div></div></div><div class="text-center pt-2"></div><div class="container py-4"><div class="row justify-content-center"><div class="col-md-4 text-center"><div class=pb-2><a href=https://abelsiqueira.com title="Abel Soares Siqueira"><img alt="Footer logo" src=/images/icon.png height=40px width=40px></a></div>&copy; 2023 All rights reserved<div class=text-secondary>Made with
<span class=text-danger>&#10084;
</span>and
<a href=https://github.com/gurusabarish/hugo-profile target=_blank title="Designed and developed by gurusabarish">Hugo Profile</a></div></div></div></div></footer><script src=/bootstrap-5/js/bootstrap.bundle.min.js></script><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))});var tooltipTriggerList=[].slice.call(document.querySelectorAll('[data-bs-toggle="tooltip"]')),tooltipList=tooltipTriggerList.map(function(e){return new bootstrap.Tooltip(e)})</script><script src=/js/search.js></script><section id=search-content class=py-2><div class=container id=search-results></div></section></body></html>